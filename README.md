# Qwen2.5-Omni-7B STT API

**Qwen2.5-Omni-7B STT API** — это серверное приложение на FastAPI для транскрипции аудиофайлов в текст с помощью модели [Qwen/Qwen2.5-Omni-7B](https://huggingface.co/Qwen/Qwen2.5-Omni-7B). Поддерживается пакетная обработка длинных аудиофайлов, автоматическое разбиение на чанки и детальная настройка параметров через API.

---

## Возможности

- Транскрипция русскоязычной речи с высокой точностью.
- Поддержка длинных аудиофайлов: автоматическое разбиение на перекрывающиеся чанки.
- Параметризация chunk-обработки (длина чанка, оверлап, размер батча и др.).
- Гибкая настройка system prompt и prompt для управления стилем распознавания.
- Асинхронный запуск на FastAPI, удобная интеграция и расширяемость.
- REST API с документацией OpenAPI (Swagger).

---

## Быстрый старт

### 1. Клонирование репозитория
Не прикладываю `requirements.txt`
Обратитесь к мануалу https://huggingface.co/Qwen/Qwen2.5-Omni-7B и следуйте рекомендациям.
> Для корректной работы потребуется CUDA-драйвер для GPU и flash_attention_2.

---

### 2. Запуск сервера

```bash
python test_apo_server.py
```
Модель будет автоматически загрузена из HuggingFace при первом запуске (по умолчанию `"Qwen/Qwen2.5-Omni-7B"`).  
Можно заранее загрузить модель в папку `./models`

FastAPI-сервер стартует по адресу [http://localhost:8000](http://localhost:8000).

---

## Использование API

### Эндпоинты

#### 1. Проверка работоспособности

```
GET /
```
**Ответ:**
```json
{"message": "Qwen Omni STT API is running."}
```

#### 2. Транскрипция аудиофайла

```
POST /transcribe/
```

**Параметры формы:**
- `audio_file` — (файл, обяз.) Аудиофайл (`wav`, `mp3`, ...).
- `prompt` — (необяз.) Промпт для модели (по умолчанию: "Transcribe the Russian audio into text with correct punctuation...").
- `sys_prompt` — (необяз.) Системный промпт (по умолчанию: "You are a highly accurate speech recognition model...").
- `chunk_duration` — (необяз.) Длина чанка в секундах (по умолчанию: 30).
- `overlap_seconds` — (необяз.) Перекрытие между чанками в секундах (по умолчанию: 2).
- `batch_size` — (необяз.) Размер батча (по умолчанию: 8).

**Пример запроса (cURL):**
```bash
curl -X POST "http://localhost:8000/transcribe/" \
  -F "audio_file=@/path/to/audio.wav" \
  -F "prompt=Транскрибируй аудио на русском с пунктуацией" \
  -F "chunk_duration=30" \
  -F "overlap_seconds=2"
```

**Пример ответа:**
```json
{
  "transcription": "Добрый день! Это пример транскрипции аудиофайла...",
  "processing_time_seconds": 12.34
}
```

---

## Архитектура

- **test_apo_server.py** — основной FastAPI-сервер, реализует загрузку модели, эндпоинты и обработку аудиочанков.
- **inference.py** — функция инференса для модели Qwen2.5-Omni, учитывает работу с GPU/CPU и корректную обработку данных.
- **models/** — папка для хранения скачанных моделей (опционально).

---

## Рекомендации по эксплуатации

- Для ускорения инференса используйте GPU (CUDA).
- Не запускайте сервер с параметром `allow_origins=["*"]` в продакшене.
- Для улучшения результатов подбирайте параметры `chunk_duration`, `overlap_seconds` под длину и качество аудио.
- При ошибках смотрите логи консоли.

---

## Благодарности

- [Qwen Team](https://huggingface.co/Qwen) за открытый доступ к Qwen2.5-Omni-7B.
- [HuggingFace Transformers](https://github.com/huggingface/transformers).
- [FastAPI](https://fastapi.tiangolo.com/).
